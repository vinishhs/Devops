ğŸ“¦ Ansible Automation Process

Ansible is an agentless automation tool used for:

Configuration management

Application deployment

Provisioning

Orchestration

It connects to target machines using SSH and executes tasks defined in YAML playbooks.

ğŸ§­ Step-by-Step Ansible Flow
1ï¸âƒ£ Install Ansible (Control Node)

Install Ansible on the machine from where automation will run.

sudo apt update
sudo apt install ansible -y

Verify
ansible --version

2ï¸âƒ£ Prepare Managed Nodes

Ensure the target systems have:

SSH enabled

Python installed

Network connectivity from control node

Test manually
ssh user@target-ip


If login works without issues, Ansible can manage the host.

3ï¸âƒ£ Create Inventory File

Inventory defines which machines Ansible should manage.

Default location:

/etc/ansible/hosts


Example:

[web]
192.168.1.10

[db]
192.168.1.20


You can also create a custom inventory file.

4ï¸âƒ£ Test Connectivity (Ping Module)
ansible all -m ping


Expected result:

SUCCESS


This confirms SSH + Python access.

5ï¸âƒ£ Write a Playbook

Playbooks are written in YAML and describe the desired state.

Example â€“ install_nginx.yml
---
- name: Install Nginx
  hosts: web
  become: yes

  tasks:
    - name: Install nginx
      apt:
        name: nginx
        state: present

6ï¸âƒ£ Run the Playbook
ansible-playbook install_nginx.yml


Ansible will:

Connect to hosts

Execute tasks

Show results

7ï¸âƒ£ Verify Changes

Login to the managed node and confirm.

systemctl status nginx


Or check in browser:

http://<server-ip>

ğŸ§  What Happens Internally?

Reads inventory

Connects via SSH

Transfers module

Executes tasks

Returns output

Cleans temporary files

No agent installation required.

ğŸ“ Recommended Project Structure
ansible-project/
â”‚â”€â”€ inventory
â”‚â”€â”€ playbook.yml
â”‚â”€â”€ roles/
â”‚â”€â”€ group_vars/
â”‚â”€â”€ host_vars/


This structure helps in organizing large environments.

ğŸš€ Common Ad-Hoc Commands

Ad-hoc commands are one-time operations without writing playbooks.

Install Package
ansible web -m apt -a "name=git state=present" --become

Restart Service
ansible web -m service -a "name=nginx state=restarted" --become

Check Disk Space
ansible all -m command -a "df -h"

ğŸ” Key Features of Ansible

âœ” Agentless architecture
âœ” Uses SSH (secure)
âœ” Human-readable YAML
âœ” Idempotent (no repeated unnecessary changes)
âœ” Easy to scale to hundreds of servers
âœ” Strong community modules

ğŸ¯ Skills Gained

Setting up control & managed nodes

Writing playbooks

Using modules

Automating installations

Running ad-hoc commands

Understanding infrastructure automation






  ğŸš€ Jenkins Freestyle Job â€“ GitHub Integration
ğŸ¯ Goal

Connect a GitHub repository to Jenkins and verify that the code is successfully cloned into the Jenkins workspace.

Flow

GitHub â†’ Jenkins Freestyle Job â†’ Workspace

âœ… Step 1 â€“ Ensure Git is Installed on Jenkins Machine

In Ubuntu VM:

git --version


If not installed:

sudo apt install git -y


Git is mandatory because Jenkins uses it to clone repositories.

âœ… Step 2 â€“ Add GitHub Token in Jenkins

Open Jenkins:

Manage Jenkins â†’ Credentials â†’ Global â†’ Add Credentials

Choose:

Kind â†’ Username with password


Fill:

Field	Value
Username	vinish (your GitHub username)
Password	GitHub Personal Access Token
ID	github-token

Click Save.

ğŸ’¡ Where to Get Token?

GitHub â†’ Settings â†’ Developer Settings â†’ Personal Access Tokens.

âœ… Step 3 â€“ Create Freestyle Project

Jenkins Dashboard â†’ New Item

Enter name:

git-trial


Select:

Freestyle project


Click OK.

âœ… Step 4 â€“ Configure Source Code Management

Inside job configuration:

Source Code Management â†’ Select Git
Repository URL

Example:

https://github.com/vinish/terraform-dev.git

Credentials

Choose:

github-token

âœ… Step 5 â€“ Add Build Step (Verify Clone)

Scroll â†’ Build â†’ Add build step â†’ Execute shell

Add commands:

pwd
ls -l


This helps confirm files are present in workspace.

âœ… Step 6 â€“ Save Job

Click Save.

âœ… Step 7 â€“ Build Now ğŸš€

Click Build Now.

After completion:
Open build â†’ Console Output.

ğŸ‰ Expected Result

You should see:

Repository cloning

Workspace path

List of project files

Example:

/var/lib/jenkins/workspace/git-trial
Dockerfile
app.js
package.json

ğŸ§  What You Learned

How Jenkins authenticates with GitHub

How repositories are cloned

Workspace concept

How to verify build execution


  ğŸ“Œ What is Terraform?

Terraform is an Infrastructure as Code (IaC) tool used to define, provision, and manage cloud and on-prem resources using configuration files.

Instead of manually creating servers, networks, or security groups, we write code.

ğŸ§­ Terraform Workflow
Write â†’ Init â†’ Validate â†’ Plan â†’ Apply â†’ Verify â†’ Destroy (if needed)

1ï¸âƒ£ Write Configuration Files

Create .tf files describing the infrastructure.

Example resources:

Provider (AWS/Azure/GCP)

Virtual machines / EC2

Security groups

Key pairs

Networks

Example:

provider "aws" {
  region = "ap-south-1"
}

resource "aws_instance" "myvm" {
  ami           = "ami-xxxxxxxx"
  instance_type = "t3.micro"
}

2ï¸âƒ£ Initialize Terraform
terraform init


What happens:

Downloads provider plugins

Prepares backend

Creates .terraform folder

Locks provider versions

Run this first time or whenever providers change.

3ï¸âƒ£ Validate Configuration
terraform validate


Checks:
âœ” syntax
âœ” required arguments
âœ” internal consistency

Does not contact cloud.

4ï¸âƒ£ Preview Changes (Execution Plan)
terraform plan


Shows:

What will be created

What will be modified

What will be destroyed

No resources are built yet.

Think of it as a dry run.

5ï¸âƒ£ Apply Changes
terraform apply


Terraform will:

Ask for confirmation

Create resources in the cloud

Generate/update terraform.tfstate

You can skip confirmation:

terraform apply -auto-approve

6ï¸âƒ£ Verify Resources

After apply:

Login to cloud console

Check instances

Verify IP, security rules, etc.

7ï¸âƒ£ Update Infrastructure

Modify .tf files â†’ run:

terraform plan
terraform apply


Terraform compares state vs new config and adjusts.

8ï¸âƒ£ Destroy Infrastructure (Avoid Billing ğŸ’°)
terraform destroy


Deletes everything defined in .tf files.

Useful for:

Labs

Practice

Avoiding unexpected charges

ğŸ“‚ Important Terraform Files
File	Purpose
.tf	Infrastructure definition
terraform.tfstate	Current infrastructure record
.terraform/	Provider plugins
terraform.tfvars	Variable values
ğŸ§  Terraform Core Concepts

Providers

Resources

Variables

Outputs

State management

Execution plan

âš¡ Quick Command Summary
terraform init
terraform validate
terraform plan
terraform apply
terraform destroy



ğŸ” Masterâ€“Slave Architecture

Masterâ€“Slave (also called Primaryâ€“Replica or Leaderâ€“Follower) is a system design where one main node controls and other nodes follow its instructions.

It is widely used in databases, distributed systems, and DevOps pipelines.

ğŸ“Œ Basic Idea

Master â†’ makes decisions, accepts writes/updates

Slaves â†’ replicate data, serve reads, execute assigned tasks

ğŸ§­ How It Works
Client â†’ Master â†’ Slaves
           â†“
       Replication


Client sends request to Master.

Master processes it.

Changes are copied to Slave nodes.

Slaves stay synchronized.

ğŸ¯ Responsibilities
Master Node

Accepts write operations

Maintains authoritative data

Sends updates to slaves

Handles coordination

Slave Nodes

Receive replicated data

Serve read requests

Provide backup / redundancy

Reduce master load

âœ… Advantages

âœ” High availability
âœ” Load balancing
âœ” Backup & recovery
âœ” Better performance for reads
âœ” Scalability

âŒ Disadvantages

âŒ Master is single point of failure (if no failover)
âŒ Replication delay may occur
âŒ Setup can be complex

ğŸ§± Real-World Examples

Masterâ€“Slave is used in:

MySQL replication

Redis primaryâ€“replica

Apache Hadoop NameNode & DataNodes

CI/CD controller & agents

ğŸ”„ Failover (Advanced)

If Master fails:

One Slave can be promoted as new Master

System continues working

This improves reliability.

ğŸ“Š Use Cases

Database replication

Distributed computing

Data backup

Read-heavy applications

Cluster management
